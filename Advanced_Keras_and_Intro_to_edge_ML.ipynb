{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Advanced Keras and Intro to edge ML.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOI65fMEZkZqqwP/f+ji2gU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbrahamKong/CMPE258-Advanced_Keras_and_Intro_to_edge_ML/blob/main/Advanced_Keras_and_Intro_to_edge_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# advanced Keras deep learning constructs concepts"
      ],
      "metadata": {
        "id": "dB2wcAvcd6RJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up"
      ],
      "metadata": {
        "id": "LpEb2VccwMlZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "G6xF4yxywDFw"
      },
      "outputs": [],
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "%load_ext tensorboard\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"deep\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Doc8t6BRwDFy"
      },
      "source": [
        "### Vanishing/Exploding Gradients Problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iRBG4ShpwDFz"
      },
      "outputs": [],
      "source": [
        "def logit(z):\n",
        "    return 1 / (1 + np.exp(-z))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "y3kkJf8hwDFz",
        "outputId": "eaa0127a-da06-4d7d-eab7-0a81ef81f8c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving figure sigmoid_saturation_plot\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;31mSystemError\u001b[0m: <built-in method write of _io.BufferedWriter object at 0x7fdfa8a71e90> returned a result with an error set",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;31mSystemError\u001b[0m: <built-in method write of _io.BufferedWriter object at 0x7fdfa8a71e90> returned a result with an error set",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;31mSystemError\u001b[0m: <built-in method write of _io.FileIO object at 0x7fdf26babeb0> returned a result with an error set",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;31mSystemError\u001b[0m: <built-in method write of _io.BufferedWriter object at 0x7fdfa8a71e90> returned a result with an error set",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;31mSystemError\u001b[0m: <built-in method write of _io.BufferedWriter object at 0x7fdfa8a71e90> returned a result with an error set",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-3d8794625e3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0msave_fig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sigmoid_saturation_plot\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-a40c7f468b26>\u001b[0m in \u001b[0;36msave_fig\u001b[0;34m(fig_id, tight_layout, fig_extension, resolution)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtight_layout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfig_extension\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresolution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# need this if 'transparent=True' to reset colors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   2201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframeon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2203\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframeon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2124\u001b[0m                     \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2125\u001b[0m                     \u001b[0mbbox_inches_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2126\u001b[0;31m                     **kwargs)\n\u001b[0m\u001b[1;32m   2127\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2128\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    535\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_file_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m                 _png.write_png(renderer._renderer, fh, self.figure.dpi,\n\u001b[0;32m--> 537\u001b[0;31m                                metadata={**default_metadata, **metadata})\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprint_to_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemError\u001b[0m: <built-in method write of _io.BufferedWriter object at 0x7fdfa8a71e90> returned a result with an error set"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "z = np.linspace(-5, 5, 200)\n",
        "\n",
        "plt.plot([-5, 5], [0, 0], 'k-')\n",
        "plt.plot([-5, 5], [1, 1], 'k--')\n",
        "plt.plot([0, 0], [-0.2, 1.2], 'k-')\n",
        "plt.plot([-5, 5], [-3/4, 7/4], 'g--')\n",
        "plt.plot(z, logit(z), \"b-\", linewidth=2)\n",
        "props = dict(facecolor='black', shrink=0.1)\n",
        "plt.annotate('Saturating', xytext=(3.5, 0.7), xy=(5, 1), arrowprops=props, fontsize=14, ha=\"center\")\n",
        "plt.annotate('Saturating', xytext=(-3.5, 0.3), xy=(-5, 0), arrowprops=props, fontsize=14, ha=\"center\")\n",
        "plt.annotate('Linear', xytext=(2, 0.2), xy=(0, 0.5), arrowprops=props, fontsize=14, ha=\"center\")\n",
        "plt.grid(True)\n",
        "plt.title(\"Sigmoid activation function\", fontsize=14)\n",
        "plt.axis([-5, 5, -0.2, 1.2])\n",
        "\n",
        "save_fig(\"sigmoid_saturation_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqUALGIMwDF0"
      },
      "source": [
        "### Xavier and He Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URGrfmViwDF1"
      },
      "outputs": [],
      "source": [
        "[name for name in dir(keras.initializers) if not name.startswith(\"_\")]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07k7pTFtwDF1"
      },
      "outputs": [],
      "source": [
        "keras.layers.Dense(10, activation=\"relu\", kernel_initializer=\"he_normal\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aa_TiIz2wDF2"
      },
      "outputs": [],
      "source": [
        "init = keras.initializers.VarianceScaling(scale=2., mode='fan_avg',\n",
        "                                          distribution='uniform')\n",
        "keras.layers.Dense(10, activation=\"relu\", kernel_initializer=init)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQidQLCEwDF-"
      },
      "source": [
        "## Batch Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_m64K7hwDF-"
      },
      "outputs": [],
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dense(300, activation=\"relu\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NI1zyFJpwDF-"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLStfWUDwDF_"
      },
      "outputs": [],
      "source": [
        "bn1 = model.layers[1]\n",
        "[(var.name, var.trainable) for var in bn1.variables]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IK2sxGr0wDF_"
      },
      "outputs": [],
      "source": [
        "#bn1.updates #deprecated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Jy_hwU3wDF_"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34Q3zRGOwDF_"
      },
      "outputs": [],
      "source": [
        "history = model.fit(X_train, y_train, epochs=10,\n",
        "                    validation_data=(X_valid, y_valid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCXmJ3WXwDF_"
      },
      "source": [
        "Sometimes applying BN before the activation function works better (there's a debate on this topic). Moreover, the layer before a `BatchNormalization` layer does not need to have bias terms, since the `BatchNormalization` layer has some as well, it would be a waste of parameters, so you can set `use_bias=False` when creating those layers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCJTiBuzwDF_"
      },
      "outputs": [],
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dense(300, use_bias=False),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Activation(\"relu\"),\n",
        "    keras.layers.Dense(100, use_bias=False),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Activation(\"relu\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyEKnWN_wDF_"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-ehe3ZdwDF_"
      },
      "outputs": [],
      "source": [
        "history = model.fit(X_train, y_train, epochs=10,\n",
        "                    validation_data=(X_valid, y_valid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFE50ZErwDGA"
      },
      "source": [
        "## Gradient Clipping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7-l0scawDGA"
      },
      "source": [
        "All Keras optimizers accept `clipnorm` or `clipvalue` arguments:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1BkzThOwDGA"
      },
      "outputs": [],
      "source": [
        "optimizer = keras.optimizers.SGD(clipvalue=1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7mBwG2OwDGA"
      },
      "outputs": [],
      "source": [
        "optimizer = keras.optimizers.SGD(clipnorm=1.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_RNG7wTwDGF"
      },
      "source": [
        "## Faster Optimizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbfeufWOwDGH"
      },
      "source": [
        "### Learning Rate Scheduling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utmpiej_wDGH"
      },
      "source": [
        "#### Power Scheduling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRF7bathwDGH"
      },
      "source": [
        "```lr = lr0 / (1 + steps / s)**c```\n",
        "* Keras uses `c=1` and `s = 1 / decay`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxFNNxGEwDGH"
      },
      "outputs": [],
      "source": [
        "optimizer = keras.optimizers.SGD(learning_rate=0.01, decay=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrjpWTXAwDGH"
      },
      "outputs": [],
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7gb2-OXwDGH"
      },
      "outputs": [],
      "source": [
        "n_epochs = 25\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
        "                    validation_data=(X_valid_scaled, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rS66Si8PwDGH"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "learning_rate = 0.01\n",
        "decay = 1e-4\n",
        "batch_size = 32\n",
        "n_steps_per_epoch = math.ceil(len(X_train) / batch_size)\n",
        "epochs = np.arange(n_epochs)\n",
        "lrs = learning_rate / (1 + decay * epochs * n_steps_per_epoch)\n",
        "\n",
        "plt.plot(epochs, lrs,  \"o-\")\n",
        "plt.axis([0, n_epochs - 1, 0, 0.01])\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.title(\"Power Scheduling\", fontsize=14)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3wL4omNwDGI"
      },
      "source": [
        "#### Exponential Scheduling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PIVbTaxwDGI"
      },
      "source": [
        "```lr = lr0 * 0.1**(epoch / s)```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FQECGcywDGI"
      },
      "outputs": [],
      "source": [
        "def exponential_decay_fn(epoch):\n",
        "    return 0.01 * 0.1**(epoch / 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHhG_uRzwDGI"
      },
      "outputs": [],
      "source": [
        "def exponential_decay(lr0, s):\n",
        "    def exponential_decay_fn(epoch):\n",
        "        return lr0 * 0.1**(epoch / s)\n",
        "    return exponential_decay_fn\n",
        "\n",
        "exponential_decay_fn = exponential_decay(lr0=0.01, s=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhHzB7FEwDGI"
      },
      "outputs": [],
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
        "n_epochs = 25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DKQorfewDGI"
      },
      "outputs": [],
      "source": [
        "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
        "                    validation_data=(X_valid_scaled, y_valid),\n",
        "                    callbacks=[lr_scheduler])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3i0FzMMwDGI"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.epoch, history.history[\"lr\"], \"o-\")\n",
        "plt.axis([0, n_epochs - 1, 0, 0.011])\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.title(\"Exponential Scheduling\", fontsize=14)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NESQo3F9wDGJ"
      },
      "source": [
        "The schedule function can take the current learning rate as a second argument:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQuDYMErwDGJ"
      },
      "outputs": [],
      "source": [
        "def exponential_decay_fn(epoch, lr):\n",
        "    return lr * 0.1**(1 / 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdxAr-IgwDGJ"
      },
      "source": [
        "If you want to update the learning rate at each iteration rather than at each epoch, you must write your own callback class:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZVHOF45wDGJ"
      },
      "outputs": [],
      "source": [
        "K = keras.backend\n",
        "\n",
        "class ExponentialDecay(keras.callbacks.Callback):\n",
        "    def __init__(self, s=40000):\n",
        "        super().__init__()\n",
        "        self.s = s\n",
        "\n",
        "    def on_batch_begin(self, batch, logs=None):\n",
        "        # Note: the `batch` argument is reset at each epoch\n",
        "        lr = K.get_value(self.model.optimizer.learning_rate)\n",
        "        K.set_value(self.model.optimizer.learning_rate, lr * 0.1**(1 / self.s))\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        logs['lr'] = K.get_value(self.model.optimizer.learning_rate)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "lr0 = 0.01\n",
        "optimizer = keras.optimizers.Nadam(learning_rate=lr0)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "n_epochs = 25\n",
        "\n",
        "s = 20 * len(X_train) // 32 # number of steps in 20 epochs (batch size = 32)\n",
        "exp_decay = ExponentialDecay(s)\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
        "                    validation_data=(X_valid_scaled, y_valid),\n",
        "                    callbacks=[exp_decay])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0NCRqoqwDGJ"
      },
      "outputs": [],
      "source": [
        "n_steps = n_epochs * len(X_train) // 32\n",
        "steps = np.arange(n_steps)\n",
        "lrs = lr0 * 0.1**(steps / s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "TRlONBwiwDGJ"
      },
      "outputs": [],
      "source": [
        "plt.plot(steps, lrs, \"-\", linewidth=2)\n",
        "plt.axis([0, n_steps - 1, 0, lr0 * 1.1])\n",
        "plt.xlabel(\"Batch\")\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.title(\"Exponential Scheduling (per batch)\", fontsize=14)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSgF9sKBwDGJ"
      },
      "source": [
        "#### Piecewise Constant Scheduling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QoV_Nw4wDGK"
      },
      "outputs": [],
      "source": [
        "def piecewise_constant_fn(epoch):\n",
        "    if epoch < 5:\n",
        "        return 0.01\n",
        "    elif epoch < 15:\n",
        "        return 0.005\n",
        "    else:\n",
        "        return 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBXY6gTiwDGK"
      },
      "outputs": [],
      "source": [
        "def piecewise_constant(boundaries, values):\n",
        "    boundaries = np.array([0] + boundaries)\n",
        "    values = np.array(values)\n",
        "    def piecewise_constant_fn(epoch):\n",
        "        return values[np.argmax(boundaries > epoch) - 1]\n",
        "    return piecewise_constant_fn\n",
        "\n",
        "piecewise_constant_fn = piecewise_constant([5, 15], [0.01, 0.005, 0.001])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TaiS8-S9wDGK"
      },
      "outputs": [],
      "source": [
        "lr_scheduler = keras.callbacks.LearningRateScheduler(piecewise_constant_fn)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
        "n_epochs = 25\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
        "                    validation_data=(X_valid_scaled, y_valid),\n",
        "                    callbacks=[lr_scheduler])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDj75y_PwDGK"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.epoch, [piecewise_constant_fn(epoch) for epoch in history.epoch], \"o-\")\n",
        "plt.axis([0, n_epochs - 1, 0, 0.011])\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.title(\"Piecewise Constant Scheduling\", fontsize=14)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZRr67DdwDGK"
      },
      "source": [
        "#### Performance Scheduling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6e8PrjfowDGK"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqJM0X1YwDGL"
      },
      "outputs": [],
      "source": [
        "lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "optimizer = keras.optimizers.SGD(learning_rate=0.02, momentum=0.9)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "n_epochs = 25\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
        "                    validation_data=(X_valid_scaled, y_valid),\n",
        "                    callbacks=[lr_scheduler])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XThSd97pwDGL"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.epoch, history.history[\"lr\"], \"bo-\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Learning Rate\", color='b')\n",
        "plt.tick_params('y', colors='b')\n",
        "plt.gca().set_xlim(0, n_epochs - 1)\n",
        "plt.grid(True)\n",
        "\n",
        "ax2 = plt.gca().twinx()\n",
        "ax2.plot(history.epoch, history.history[\"val_loss\"], \"r^-\")\n",
        "ax2.set_ylabel('Validation Loss', color='r')\n",
        "ax2.tick_params('y', colors='r')\n",
        "\n",
        "plt.title(\"Reduce LR on Plateau\", fontsize=14)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ag7OxKEmwDGL"
      },
      "source": [
        "#### tf.keras schedulers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXHPnSKOwDGL"
      },
      "outputs": [],
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "s = 20 * len(X_train) // 32 # number of steps in 20 epochs (batch size = 32)\n",
        "learning_rate = keras.optimizers.schedules.ExponentialDecay(0.01, s, 0.1)\n",
        "optimizer = keras.optimizers.SGD(learning_rate)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "n_epochs = 25\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
        "                    validation_data=(X_valid_scaled, y_valid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO9B5TdcwDGL"
      },
      "source": [
        "For piecewise constant scheduling, try this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPHblkZzwDGL"
      },
      "outputs": [],
      "source": [
        "learning_rate = keras.optimizers.schedules.PiecewiseConstantDecay(\n",
        "    boundaries=[5. * n_steps_per_epoch, 15. * n_steps_per_epoch],\n",
        "    values=[0.01, 0.005, 0.001])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyVZJBpZwDGM"
      },
      "source": [
        "#### 1Cycle scheduling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDYYiPxtwDGM"
      },
      "outputs": [],
      "source": [
        "K = keras.backend\n",
        "\n",
        "class ExponentialLearningRate(keras.callbacks.Callback):\n",
        "    def __init__(self, factor):\n",
        "        self.factor = factor\n",
        "        self.rates = []\n",
        "        self.losses = []\n",
        "    def on_batch_end(self, batch, logs):\n",
        "        self.rates.append(K.get_value(self.model.optimizer.learning_rate))\n",
        "        self.losses.append(logs[\"loss\"])\n",
        "        K.set_value(self.model.optimizer.learning_rate, self.model.optimizer.learning_rate * self.factor)\n",
        "\n",
        "def find_learning_rate(model, X, y, epochs=1, batch_size=32, min_rate=10**-5, max_rate=10):\n",
        "    init_weights = model.get_weights()\n",
        "    iterations = math.ceil(len(X) / batch_size) * epochs\n",
        "    factor = np.exp(np.log(max_rate / min_rate) / iterations)\n",
        "    init_lr = K.get_value(model.optimizer.learning_rate)\n",
        "    K.set_value(model.optimizer.learning_rate, min_rate)\n",
        "    exp_lr = ExponentialLearningRate(factor)\n",
        "    history = model.fit(X, y, epochs=epochs, batch_size=batch_size,\n",
        "                        callbacks=[exp_lr])\n",
        "    K.set_value(model.optimizer.learning_rate, init_lr)\n",
        "    model.set_weights(init_weights)\n",
        "    return exp_lr.rates, exp_lr.losses\n",
        "\n",
        "def plot_lr_vs_loss(rates, losses):\n",
        "    plt.plot(rates, losses)\n",
        "    plt.gca().set_xscale('log')\n",
        "    plt.hlines(min(losses), min(rates), max(rates))\n",
        "    plt.axis([min(rates), max(rates), min(losses), (losses[0] + min(losses)) / 2])\n",
        "    plt.xlabel(\"Learning rate\")\n",
        "    plt.ylabel(\"Loss\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNWKmiBmwDGM"
      },
      "source": [
        "**Warning**: In the `on_batch_end()` method, `logs[\"loss\"]` used to contain the batch loss, but in TensorFlow 2.2.0 it was replaced with the mean loss (since the start of the epoch). This explains why the graph below is much smoother than in the book (if you are using TF 2.2 or above). It also means that there is a lag between the moment the batch loss starts exploding and the moment the explosion becomes clear in the graph. So you should choose a slightly smaller learning rate than you would have chosen with the \"noisy\" graph. Alternatively, you can tweak the `ExponentialLearningRate` callback above so it computes the batch loss (based on the current mean loss and the previous mean loss):\n",
        "\n",
        "```python\n",
        "class ExponentialLearningRate(keras.callbacks.Callback):\n",
        "    def __init__(self, factor):\n",
        "        self.factor = factor\n",
        "        self.rates = []\n",
        "        self.losses = []\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        self.prev_loss = 0\n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        batch_loss = logs[\"loss\"] * (batch + 1) - self.prev_loss * batch\n",
        "        self.prev_loss = logs[\"loss\"]\n",
        "        self.rates.append(K.get_value(self.model.optimizer.learning_rate))\n",
        "        self.losses.append(batch_loss)\n",
        "        K.set_value(self.model.optimizer.learning_rate, self.model.optimizer.learning_rate * self.factor)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onHKo5AtwDGM"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unLphNIPwDGM"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "rates, losses = find_learning_rate(model, X_train_scaled, y_train, epochs=1, batch_size=batch_size)\n",
        "plot_lr_vs_loss(rates, losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9GOeJ8-wDGM"
      },
      "outputs": [],
      "source": [
        "class OneCycleScheduler(keras.callbacks.Callback):\n",
        "    def __init__(self, iterations, max_rate, start_rate=None,\n",
        "                 last_iterations=None, last_rate=None):\n",
        "        self.iterations = iterations\n",
        "        self.max_rate = max_rate\n",
        "        self.start_rate = start_rate or max_rate / 10\n",
        "        self.last_iterations = last_iterations or iterations // 10 + 1\n",
        "        self.half_iteration = (iterations - self.last_iterations) // 2\n",
        "        self.last_rate = last_rate or self.start_rate / 1000\n",
        "        self.iteration = 0\n",
        "    def _interpolate(self, iter1, iter2, rate1, rate2):\n",
        "        return ((rate2 - rate1) * (self.iteration - iter1)\n",
        "                / (iter2 - iter1) + rate1)\n",
        "    def on_batch_begin(self, batch, logs):\n",
        "        if self.iteration < self.half_iteration:\n",
        "            rate = self._interpolate(0, self.half_iteration, self.start_rate, self.max_rate)\n",
        "        elif self.iteration < 2 * self.half_iteration:\n",
        "            rate = self._interpolate(self.half_iteration, 2 * self.half_iteration,\n",
        "                                     self.max_rate, self.start_rate)\n",
        "        else:\n",
        "            rate = self._interpolate(2 * self.half_iteration, self.iterations,\n",
        "                                     self.start_rate, self.last_rate)\n",
        "        self.iteration += 1\n",
        "        K.set_value(self.model.optimizer.learning_rate, rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJk-WheNwDGN"
      },
      "outputs": [],
      "source": [
        "n_epochs = 25\n",
        "onecycle = OneCycleScheduler(math.ceil(len(X_train) / batch_size) * n_epochs, max_rate=0.05)\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs, batch_size=batch_size,\n",
        "                    validation_data=(X_valid_scaled, y_valid),\n",
        "                    callbacks=[onecycle])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Drop Out"
      ],
      "metadata": {
        "id": "tsRzwpfnMqtJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hqo1YF17wDGQ"
      },
      "outputs": [],
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dropout(rate=0.2),\n",
        "    keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
        "    keras.layers.Dropout(rate=0.2),\n",
        "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
        "    keras.layers.Dropout(rate=0.2),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
        "n_epochs = 2\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
        "                    validation_data=(X_valid_scaled, y_valid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2MTtMwHwDGR"
      },
      "source": [
        "### Alpha Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJNHx8zawDGR"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qplPQq6QwDGR"
      },
      "outputs": [],
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.AlphaDropout(rate=0.2),\n",
        "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.AlphaDropout(rate=0.2),\n",
        "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.AlphaDropout(rate=0.2),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "optimizer = keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "n_epochs = 20\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
        "                    validation_data=(X_valid_scaled, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcpWUOGQwDGR"
      },
      "outputs": [],
      "source": [
        "model.evaluate(X_test_scaled, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EyzG-JdIwDGR"
      },
      "outputs": [],
      "source": [
        "model.evaluate(X_train_scaled, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81TZFl6iwDGR"
      },
      "outputs": [],
      "source": [
        "history = model.fit(X_train_scaled, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8zunyIcwDGS"
      },
      "source": [
        "### MC Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VoqLiDzvwDGS"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tw3YbnEwDGS"
      },
      "outputs": [],
      "source": [
        "y_probas = np.stack([model(X_test_scaled, training=True)\n",
        "                     for sample in range(100)])\n",
        "y_proba = y_probas.mean(axis=0)\n",
        "y_std = y_probas.std(axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4u5kh1GswDGS"
      },
      "outputs": [],
      "source": [
        "np.round(model.predict(X_test_scaled[:1]), 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7y9ErjFwDGT"
      },
      "outputs": [],
      "source": [
        "np.round(y_probas[:, :1], 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjavvg8MwDGT"
      },
      "outputs": [],
      "source": [
        "np.round(y_proba[:1], 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cinAucywDGT"
      },
      "outputs": [],
      "source": [
        "y_std = y_probas.std(axis=0)\n",
        "np.round(y_std[:1], 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OnEDWzawDGT"
      },
      "outputs": [],
      "source": [
        "y_pred = np.argmax(y_proba, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ut3wrxKlwDGU"
      },
      "outputs": [],
      "source": [
        "accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
        "accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nlm785WcwDGU"
      },
      "outputs": [],
      "source": [
        "class MCDropout(keras.layers.Dropout):\n",
        "    def call(self, inputs):\n",
        "        return super().call(inputs, training=True)\n",
        "\n",
        "class MCAlphaDropout(keras.layers.AlphaDropout):\n",
        "    def call(self, inputs):\n",
        "        return super().call(inputs, training=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sD38eHqKwDGU"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5LGRT3DwDGU"
      },
      "outputs": [],
      "source": [
        "mc_model = keras.models.Sequential([\n",
        "    MCAlphaDropout(layer.rate) if isinstance(layer, keras.layers.AlphaDropout) else layer\n",
        "    for layer in model.layers\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RCBcbNzwDGU"
      },
      "outputs": [],
      "source": [
        "mc_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebyJuJtTwDGV"
      },
      "outputs": [],
      "source": [
        "optimizer = keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
        "mc_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYe0TpqgwDGV"
      },
      "outputs": [],
      "source": [
        "mc_model.set_weights(model.get_weights())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6d78qvlwDGV"
      },
      "source": [
        "Now we can use the model with MC Dropout:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lv3Cjru3wDGV"
      },
      "outputs": [],
      "source": [
        "np.round(np.mean([mc_model.predict(X_test_scaled[:1]) for sample in range(100)], axis=0), 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalization"
      ],
      "metadata": {
        "id": "upt-JV0BMvpb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xESY9eJQwDGV"
      },
      "source": [
        "### Max norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "js3PXEFZwDGV"
      },
      "outputs": [],
      "source": [
        "layer = keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
        "                           kernel_constraint=keras.constraints.max_norm(1.))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1b_F3gDwDGV"
      },
      "outputs": [],
      "source": [
        "MaxNormDense = partial(keras.layers.Dense,\n",
        "                       activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
        "                       kernel_constraint=keras.constraints.max_norm(1.))\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    MaxNormDense(300),\n",
        "    MaxNormDense(100),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
        "n_epochs = 2\n",
        "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
        "                    validation_data=(X_valid_scaled, y_valid))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Activation function,initializer regularizer and kernel weight constraint"
      ],
      "metadata": {
        "id": "jjAm07smM9BK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uS9SVCruwDF2"
      },
      "source": [
        "### Leaky ReLU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LhZnDZYzwDF3"
      },
      "outputs": [],
      "source": [
        "def leaky_relu(z, alpha=0.01):\n",
        "    return np.maximum(alpha*z, z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkaKmUlswDF3"
      },
      "outputs": [],
      "source": [
        "plt.plot(z, leaky_relu(z, 0.05), \"b-\", linewidth=2)\n",
        "plt.plot([-5, 5], [0, 0], 'k-')\n",
        "plt.plot([0, 0], [-0.5, 4.2], 'k-')\n",
        "plt.grid(True)\n",
        "props = dict(facecolor='black', shrink=0.1)\n",
        "plt.annotate('Leak', xytext=(-3.5, 0.5), xy=(-5, -0.2), arrowprops=props, fontsize=14, ha=\"center\")\n",
        "plt.title(\"Leaky ReLU activation function\", fontsize=14)\n",
        "plt.axis([-5, 5, -0.5, 4.2])\n",
        "\n",
        "save_fig(\"leaky_relu_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFg2a8tLwDF3"
      },
      "outputs": [],
      "source": [
        "[m for m in dir(keras.activations) if not m.startswith(\"_\")]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fsjBCkchwDF4"
      },
      "outputs": [],
      "source": [
        "[m for m in dir(keras.layers) if \"relu\" in m.lower()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4ZyqDWKwDF4"
      },
      "source": [
        "Let's train a neural network on Fashion MNIST using the Leaky ReLU:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSXOrwPuwDF4"
      },
      "outputs": [],
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "X_train_full = X_train_full / 255.0\n",
        "X_test = X_test / 255.0\n",
        "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWBoAPulwDF4"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
        "    keras.layers.LeakyReLU(),\n",
        "    keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
        "    keras.layers.LeakyReLU(),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJ00W3l9wDF4"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "vA2imRu_wDF5"
      },
      "outputs": [],
      "source": [
        "history = model.fit(X_train, y_train, epochs=10,\n",
        "                    validation_data=(X_valid, y_valid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FabGC6lqwDF5"
      },
      "source": [
        "Now let's try PReLU:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CoJ8z3SGwDF5"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
        "    keras.layers.PReLU(),\n",
        "    keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
        "    keras.layers.PReLU(),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myvodNrxwDF5"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncLGNCyOwDF5"
      },
      "outputs": [],
      "source": [
        "history = model.fit(X_train, y_train, epochs=10,\n",
        "                    validation_data=(X_valid, y_valid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAjFcOWjwDF6"
      },
      "source": [
        "### ELU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DtDW69TwwDF6"
      },
      "outputs": [],
      "source": [
        "def elu(z, alpha=1):\n",
        "    return np.where(z < 0, alpha * (np.exp(z) - 1), z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHHnyXA0wDF6"
      },
      "outputs": [],
      "source": [
        "plt.plot(z, elu(z), \"b-\", linewidth=2)\n",
        "plt.plot([-5, 5], [0, 0], 'k-')\n",
        "plt.plot([-5, 5], [-1, -1], 'k--')\n",
        "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
        "plt.grid(True)\n",
        "plt.title(r\"ELU activation function ($\\alpha=1$)\", fontsize=14)\n",
        "plt.axis([-5, 5, -2.2, 3.2])\n",
        "\n",
        "save_fig(\"elu_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1j1DgHCNwDF6"
      },
      "source": [
        "Implementing ELU in TensorFlow is trivial, just specify the activation function when building each layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-7P7LNWwDF6"
      },
      "outputs": [],
      "source": [
        "keras.layers.Dense(10, activation=\"elu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WZtYIJawDF7"
      },
      "source": [
        "### SELU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrOZeFsewDF7"
      },
      "source": [
        "This activation function was proposed in this [great paper](https://arxiv.org/pdf/1706.02515.pdf) by Günter Klambauer, Thomas Unterthiner and Andreas Mayr, published in June 2017. During training, a neural network composed exclusively of a stack of dense layers using the SELU activation function and LeCun initialization will self-normalize: the output of each layer will tend to preserve the same mean and variance during training, which solves the vanishing/exploding gradients problem. As a result, this activation function outperforms the other activation functions very significantly for such neural nets, so you should really try it out. Unfortunately, the self-normalizing property of the SELU activation function is easily broken: you cannot use ℓ<sub>1</sub> or ℓ<sub>2</sub> regularization, regular dropout, max-norm, skip connections or other non-sequential topologies (so recurrent neural networks won't self-normalize). However, in practice it works quite well with sequential CNNs. If you break self-normalization, SELU will not necessarily outperform other activation functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQzuSwTQwDF7"
      },
      "outputs": [],
      "source": [
        "from scipy.special import erfc\n",
        "\n",
        "# alpha and scale to self normalize with mean 0 and standard deviation 1\n",
        "# (see equation 14 in the paper):\n",
        "alpha_0_1 = -np.sqrt(2 / np.pi) / (erfc(1/np.sqrt(2)) * np.exp(1/2) - 1)\n",
        "scale_0_1 = (1 - erfc(1 / np.sqrt(2)) * np.sqrt(np.e)) * np.sqrt(2 * np.pi) * (2 * erfc(np.sqrt(2))*np.e**2 + np.pi*erfc(1/np.sqrt(2))**2*np.e - 2*(2+np.pi)*erfc(1/np.sqrt(2))*np.sqrt(np.e)+np.pi+2)**(-1/2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEhG9WgEwDF7"
      },
      "outputs": [],
      "source": [
        "def selu(z, scale=scale_0_1, alpha=alpha_0_1):\n",
        "    return scale * elu(z, alpha)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQRLitQSwDF7"
      },
      "outputs": [],
      "source": [
        "plt.plot(z, selu(z), \"b-\", linewidth=2)\n",
        "plt.plot([-5, 5], [0, 0], 'k-')\n",
        "plt.plot([-5, 5], [-1.758, -1.758], 'k--')\n",
        "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
        "plt.grid(True)\n",
        "plt.title(\"SELU activation function\", fontsize=14)\n",
        "plt.axis([-5, 5, -2.2, 3.2])\n",
        "\n",
        "save_fig(\"selu_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfHpZ1g-wDF8"
      },
      "source": [
        "By default, the SELU hyperparameters (`scale` and `alpha`) are tuned in such a way that the mean output of each neuron remains close to 0, and the standard deviation remains close to 1 (assuming the inputs are standardized with mean 0 and standard deviation 1 too). Using this activation function, even a 1,000 layer deep neural network preserves roughly mean 0 and standard deviation 1 across all layers, avoiding the exploding/vanishing gradients problem:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70twKdYVwDF8"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "Z = np.random.normal(size=(500, 100)) # standardized inputs\n",
        "for layer in range(1000):\n",
        "    W = np.random.normal(size=(100, 100), scale=np.sqrt(1 / 100)) # LeCun initialization\n",
        "    Z = selu(np.dot(Z, W))\n",
        "    means = np.mean(Z, axis=0).mean()\n",
        "    stds = np.std(Z, axis=0).mean()\n",
        "    if layer % 100 == 0:\n",
        "        print(\"Layer {}: mean {:.2f}, std deviation {:.2f}\".format(layer, means, stds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cfbAVtZwDF8"
      },
      "source": [
        "Using SELU is easy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmmPSVuMwDF8"
      },
      "outputs": [],
      "source": [
        "keras.layers.Dense(10, activation=\"selu\",\n",
        "                   kernel_initializer=\"lecun_normal\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLoxaLRkwDF8"
      },
      "source": [
        "Let's create a neural net for Fashion MNIST with 100 hidden layers, using the SELU activation function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eagvEwynwDF8"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8YufEbrwDF8"
      },
      "outputs": [],
      "source": [
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
        "model.add(keras.layers.Dense(300, activation=\"selu\",\n",
        "                             kernel_initializer=\"lecun_normal\"))\n",
        "for layer in range(99):\n",
        "    model.add(keras.layers.Dense(100, activation=\"selu\",\n",
        "                                 kernel_initializer=\"lecun_normal\"))\n",
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5O2JXs7ZwDF9"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFzxpv-GwDF9"
      },
      "source": [
        "Now let's train it. Do not forget to scale the inputs to mean 0 and standard deviation 1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uC61SmpkwDF9"
      },
      "outputs": [],
      "source": [
        "pixel_means = X_train.mean(axis=0, keepdims=True)\n",
        "pixel_stds = X_train.std(axis=0, keepdims=True)\n",
        "X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
        "X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
        "X_test_scaled = (X_test - pixel_means) / pixel_stds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVKo1gLIwDF9"
      },
      "outputs": [],
      "source": [
        "history = model.fit(X_train_scaled, y_train, epochs=5,\n",
        "                    validation_data=(X_valid_scaled, y_valid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wL9E0ELbwDF9"
      },
      "source": [
        "Now look at what happens if we try to use the ReLU activation function instead:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ubfy1l7swDF9"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dP1mQu_JwDF9"
      },
      "outputs": [],
      "source": [
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
        "model.add(keras.layers.Dense(300, activation=\"relu\", kernel_initializer=\"he_normal\"))\n",
        "for layer in range(99):\n",
        "    model.add(keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"))\n",
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVZyZ9x1wDF9"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dD9BHoNYwDF-"
      },
      "outputs": [],
      "source": [
        "history = model.fit(X_train_scaled, y_train, epochs=5,\n",
        "                    validation_data=(X_valid_scaled, y_valid))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up"
      ],
      "metadata": {
        "id": "Yb05SzUHO5wU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# TensorFlow ≥2.4 is required in this notebook\n",
        "# Earlier 2.x versions will mostly work the same, but with a few bugs\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.4\"\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"deep\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ],
      "metadata": {
        "id": "-HOTtqmXPDnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss Function"
      ],
      "metadata": {
        "id": "IbfE0IsBM2fF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05nbEfvzOtDQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
        "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X_train_full, y_train_full, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_valid_scaled = scaler.transform(X_valid)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7TONnWJOtDQ"
      },
      "outputs": [],
      "source": [
        "def huber_fn(y_true, y_pred):\n",
        "    error = y_true - y_pred\n",
        "    is_small_error = tf.abs(error) < 1\n",
        "    squared_loss = tf.square(error) / 2\n",
        "    linear_loss  = tf.abs(error) - 0.5\n",
        "    return tf.where(is_small_error, squared_loss, linear_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQkpMm9_OtDQ"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 3.5))\n",
        "z = np.linspace(-4, 4, 200)\n",
        "plt.plot(z, huber_fn(0, z), \"b-\", linewidth=2, label=\"huber($z$)\")\n",
        "plt.plot(z, z**2 / 2, \"b:\", linewidth=1, label=r\"$\\frac{1}{2}z^2$\")\n",
        "plt.plot([-1, -1], [0, huber_fn(0., -1.)], \"r--\")\n",
        "plt.plot([1, 1], [0, huber_fn(0., 1.)], \"r--\")\n",
        "plt.gca().axhline(y=0, color='k')\n",
        "plt.gca().axvline(x=0, color='k')\n",
        "plt.axis([-4, 4, 0, 4])\n",
        "plt.grid(True)\n",
        "plt.xlabel(\"$z$\")\n",
        "plt.legend(fontsize=14)\n",
        "plt.title(\"Huber loss\", fontsize=14)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zIFyFNYBOtDQ"
      },
      "outputs": [],
      "source": [
        "input_shape = X_train.shape[1:]\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
        "                       input_shape=input_shape),\n",
        "    keras.layers.Dense(1),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_UzvqUxNOtDQ"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=huber_fn, optimizer=\"nadam\", metrics=[\"mae\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "ElXnHCZROtDQ"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train_scaled, y_train, epochs=2,\n",
        "          validation_data=(X_valid_scaled, y_valid))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metric"
      ],
      "metadata": {
        "id": "J8Yj-PU5NAxo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uooHxtyvOtDV"
      },
      "outputs": [],
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
        "                       input_shape=input_shape),\n",
        "    keras.layers.Dense(1),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOELthFpOtDV"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[create_huber(2.0)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Cig2cqbOtDW"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train_scaled, y_train, epochs=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtFzXQ0VOtDW"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=create_huber(2.0), optimizer=\"nadam\", metrics=[create_huber(2.0)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrerr_rQOtDW"
      },
      "outputs": [],
      "source": [
        "sample_weight = np.random.rand(len(y_train))\n",
        "history = model.fit(X_train_scaled, y_train, epochs=2, sample_weight=sample_weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9cyqiwVOtDW"
      },
      "outputs": [],
      "source": [
        "history.history[\"loss\"][0], history.history[\"huber_fn\"][0] * sample_weight.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qD3frRizOtDW"
      },
      "source": [
        "### Streaming metrics (HuberMetric)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cls2AZD4OtDW"
      },
      "outputs": [],
      "source": [
        "precision = keras.metrics.Precision()\n",
        "precision([0, 1, 1, 1, 0, 1, 0, 1], [1, 1, 0, 1, 0, 1, 0, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZOvC7aDOtDX"
      },
      "outputs": [],
      "source": [
        "precision([0, 1, 0, 0, 1, 0, 1, 1], [1, 0, 1, 1, 0, 0, 0, 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txm99ulcOtDX"
      },
      "outputs": [],
      "source": [
        "precision.result()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmi68dI2OtDX"
      },
      "outputs": [],
      "source": [
        "precision.variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oD1roNd2OtDX"
      },
      "outputs": [],
      "source": [
        "precision.reset_states()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLV0tLktOtDX"
      },
      "source": [
        "Creating a streaming metric:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V34E_-siOtDX"
      },
      "outputs": [],
      "source": [
        "class HuberMetric(keras.metrics.Metric):\n",
        "    def __init__(self, threshold=1.0, **kwargs):\n",
        "        super().__init__(**kwargs) # handles base args (e.g., dtype)\n",
        "        self.threshold = threshold\n",
        "        self.huber_fn = create_huber(threshold)\n",
        "        self.total = self.add_weight(\"total\", initializer=\"zeros\")\n",
        "        self.count = self.add_weight(\"count\", initializer=\"zeros\")\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        metric = self.huber_fn(y_true, y_pred)\n",
        "        self.total.assign_add(tf.reduce_sum(metric))\n",
        "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
        "    def result(self):\n",
        "        return self.total / self.count\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        return {**base_config, \"threshold\": self.threshold}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wiUEatOnOtDX"
      },
      "outputs": [],
      "source": [
        "m = HuberMetric(2.)\n",
        "\n",
        "# total = 2 * |10 - 2| - 2²/2 = 14\n",
        "# count = 1\n",
        "# result = 14 / 1 = 14\n",
        "m(tf.constant([[2.]]), tf.constant([[10.]])) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OI0hQz9AOtDY"
      },
      "outputs": [],
      "source": [
        "# total = total + (|1 - 0|² / 2) + (2 * |9.25 - 5| - 2² / 2) = 14 + 7 = 21\n",
        "# count = count + 2 = 3\n",
        "# result = total / count = 21 / 3 = 7\n",
        "m(tf.constant([[0.], [5.]]), tf.constant([[1.], [9.25]]))\n",
        "\n",
        "m.result()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qw5aftgGOtDY"
      },
      "outputs": [],
      "source": [
        "m.variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FVcDaHNOtDY"
      },
      "outputs": [],
      "source": [
        "m.reset_states()\n",
        "m.variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptESX6e2OtDY"
      },
      "source": [
        "Let's check that the `HuberMetric` class works well:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQ1KZBqNOtDY"
      },
      "outputs": [],
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qjh9hLUfOtDY"
      },
      "outputs": [],
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
        "                       input_shape=input_shape),\n",
        "    keras.layers.Dense(1),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7xWjDOGOtDY"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=create_huber(2.0), optimizer=\"nadam\", metrics=[HuberMetric(2.0)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_A7k_reOtDZ"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train_scaled.astype(np.float32), y_train.astype(np.float32), epochs=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRLA-EjYOtDZ"
      },
      "outputs": [],
      "source": [
        "model.save(\"my_model_with_a_custom_metric.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1v4RULwOtDZ"
      },
      "outputs": [],
      "source": [
        "model = keras.models.load_model(\"my_model_with_a_custom_metric.h5\",\n",
        "                                custom_objects={\"huber_fn\": create_huber(2.0),\n",
        "                                                \"HuberMetric\": HuberMetric})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BF0OVnMJOtDZ"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train_scaled.astype(np.float32), y_train.astype(np.float32), epochs=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFsQi3hxOtDZ"
      },
      "source": [
        "**Warning**: In TF 2.2, tf.keras adds an extra first metric in `model.metrics` at position 0 (see [TF issue #38150](https://github.com/tensorflow/tensorflow/issues/38150)). This forces us to use `model.metrics[-1]` rather than `model.metrics[0]` to access the `HuberMetric`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6KJ_UYEOtDZ"
      },
      "outputs": [],
      "source": [
        "model.metrics[-1].threshold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAYkbhZcOtDZ"
      },
      "source": [
        "Looks like it works fine! More simply, we could have created the class like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQZqCyfXOtDa"
      },
      "outputs": [],
      "source": [
        "class HuberMetric(keras.metrics.Mean):\n",
        "    def __init__(self, threshold=1.0, name='HuberMetric', dtype=None):\n",
        "        self.threshold = threshold\n",
        "        self.huber_fn = create_huber(threshold)\n",
        "        super().__init__(name=name, dtype=dtype)\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        metric = self.huber_fn(y_true, y_pred)\n",
        "        super(HuberMetric, self).update_state(metric, sample_weight)\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        return {**base_config, \"threshold\": self.threshold}        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jc3sx4sLOtDa"
      },
      "source": [
        "This class handles shapes better, and it also supports sample weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KR4st8ItOtDa"
      },
      "outputs": [],
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFhesyQPOtDa"
      },
      "outputs": [],
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
        "                       input_shape=input_shape),\n",
        "    keras.layers.Dense(1),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7JGqv9LOtDa"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=keras.losses.Huber(2.0), optimizer=\"nadam\", weighted_metrics=[HuberMetric(2.0)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "3eKO18JwOtDa"
      },
      "outputs": [],
      "source": [
        "sample_weight = np.random.rand(len(y_train))\n",
        "history = model.fit(X_train_scaled.astype(np.float32), y_train.astype(np.float32),\n",
        "                    epochs=2, sample_weight=sample_weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CygttUSUOtDa"
      },
      "outputs": [],
      "source": [
        "history.history[\"loss\"][0], history.history[\"HuberMetric\"][0] * sample_weight.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otk0S_OOOtDa"
      },
      "outputs": [],
      "source": [
        "model.save(\"my_model_with_a_custom_metric_v2.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTKeeg9uOtDb"
      },
      "outputs": [],
      "source": [
        "model = keras.models.load_model(\"my_model_with_a_custom_metric_v2.h5\",\n",
        "                                custom_objects={\"HuberMetric\": HuberMetric})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJmZKMLMOtDb"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train_scaled.astype(np.float32), y_train.astype(np.float32), epochs=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "ll-reiYhOtDb"
      },
      "outputs": [],
      "source": [
        "model.metrics[-1].threshold"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "wlmmSe2ENDy_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WuIzYkznOtDf"
      },
      "outputs": [],
      "source": [
        "X_new_scaled = X_test_scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmEcNk9wOtDf"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(keras.layers.Layer):\n",
        "    def __init__(self, n_layers, n_neurons, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.hidden = [keras.layers.Dense(n_neurons, activation=\"elu\",\n",
        "                                          kernel_initializer=\"he_normal\")\n",
        "                       for _ in range(n_layers)]\n",
        "\n",
        "    def call(self, inputs):\n",
        "        Z = inputs\n",
        "        for layer in self.hidden:\n",
        "            Z = layer(Z)\n",
        "        return inputs + Z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QToywq-pOtDf"
      },
      "outputs": [],
      "source": [
        "class ResidualRegressor(keras.models.Model):\n",
        "    def __init__(self, output_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.hidden1 = keras.layers.Dense(30, activation=\"elu\",\n",
        "                                          kernel_initializer=\"he_normal\")\n",
        "        self.block1 = ResidualBlock(2, 30)\n",
        "        self.block2 = ResidualBlock(2, 30)\n",
        "        self.out = keras.layers.Dense(output_dim)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        Z = self.hidden1(inputs)\n",
        "        for _ in range(1 + 3):\n",
        "            Z = self.block1(Z)\n",
        "        Z = self.block2(Z)\n",
        "        return self.out(Z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7ZXBSYTOtDf"
      },
      "outputs": [],
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMcnxLA6OtDf"
      },
      "outputs": [],
      "source": [
        "model = ResidualRegressor(1)\n",
        "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
        "history = model.fit(X_train_scaled, y_train, epochs=5)\n",
        "score = model.evaluate(X_test_scaled, y_test)\n",
        "y_pred = model.predict(X_new_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nz5YmsucOtDf"
      },
      "outputs": [],
      "source": [
        "model.save(\"my_custom_model.ckpt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUujkiLMOtDf"
      },
      "outputs": [],
      "source": [
        "model = keras.models.load_model(\"my_custom_model.ckpt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7z-YA8O2OtDg"
      },
      "outputs": [],
      "source": [
        "history = model.fit(X_train_scaled, y_train, epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhTbqbbzOtDg"
      },
      "source": [
        "We could have defined the model using the sequential API instead:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wT8uEinzOtDg"
      },
      "outputs": [],
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJqbEPn4OtDg"
      },
      "outputs": [],
      "source": [
        "block1 = ResidualBlock(2, 30)\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
        "    block1, block1, block1, block1,\n",
        "    ResidualBlock(2, 30),\n",
        "    keras.layers.Dense(1)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_H0k2fhOtDg"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
        "history = model.fit(X_train_scaled, y_train, epochs=5)\n",
        "score = model.evaluate(X_test_scaled, y_test)\n",
        "y_pred = model.predict(X_new_scaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizer"
      ],
      "metadata": {
        "id": "HS7oVMSvNF3u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8koVkZgOtDx"
      },
      "outputs": [],
      "source": [
        "class MyMomentumOptimizer(keras.optimizers.Optimizer):\n",
        "    def __init__(self, learning_rate=0.001, momentum=0.9, name=\"MyMomentumOptimizer\", **kwargs):\n",
        "        \"\"\"Call super().__init__() and use _set_hyper() to store hyperparameters\"\"\"\n",
        "        super().__init__(name, **kwargs)\n",
        "        self._set_hyper(\"learning_rate\", kwargs.get(\"lr\", learning_rate)) # handle lr=learning_rate\n",
        "        self._set_hyper(\"decay\", self._initial_decay) # \n",
        "        self._set_hyper(\"momentum\", momentum)\n",
        "    \n",
        "    def _create_slots(self, var_list):\n",
        "        \"\"\"For each model variable, create the optimizer variable associated with it.\n",
        "        TensorFlow calls these optimizer variables \"slots\".\n",
        "        For momentum optimization, we need one momentum slot per model variable.\n",
        "        \"\"\"\n",
        "        for var in var_list:\n",
        "            self.add_slot(var, \"momentum\")\n",
        "\n",
        "    @tf.function\n",
        "    def _resource_apply_dense(self, grad, var):\n",
        "        \"\"\"Update the slots and perform one optimization step for one model variable\n",
        "        \"\"\"\n",
        "        var_dtype = var.dtype.base_dtype\n",
        "        lr_t = self._decayed_lr(var_dtype) # handle learning rate decay\n",
        "        momentum_var = self.get_slot(var, \"momentum\")\n",
        "        momentum_hyper = self._get_hyper(\"momentum\", var_dtype)\n",
        "        momentum_var.assign(momentum_var * momentum_hyper - (1. - momentum_hyper)* grad)\n",
        "        var.assign_add(momentum_var * lr_t)\n",
        "\n",
        "    def _resource_apply_sparse(self, grad, var):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        return {\n",
        "            **base_config,\n",
        "            \"learning_rate\": self._serialize_hyperparameter(\"learning_rate\"),\n",
        "            \"decay\": self._serialize_hyperparameter(\"decay\"),\n",
        "            \"momentum\": self._serialize_hyperparameter(\"momentum\"),\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phjbONeCOtDx"
      },
      "outputs": [],
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ej2ogLW9OtDx"
      },
      "outputs": [],
      "source": [
        "model = keras.models.Sequential([keras.layers.Dense(1, input_shape=[8])])\n",
        "model.compile(loss=\"mse\", optimizer=MyMomentumOptimizer())\n",
        "model.fit(X_train_scaled, y_train, epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train a model using a custom training loop to tackle the Fashion MNIST dataset"
      ],
      "metadata": {
        "id": "GZz4aDVMNHbD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXdF86cNOtDz"
      },
      "outputs": [],
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "X_train_full = X_train_full.astype(np.float32) / 255.\n",
        "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "X_test = X_test.astype(np.float32) / 255."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "An9fiZGROtDz"
      },
      "outputs": [],
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZPllpE3OtDz"
      },
      "outputs": [],
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\"),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sHvo7_OOtDz"
      },
      "outputs": [],
      "source": [
        "n_epochs = 5\n",
        "batch_size = 32\n",
        "n_steps = len(X_train) // batch_size\n",
        "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
        "loss_fn = keras.losses.sparse_categorical_crossentropy\n",
        "mean_loss = keras.metrics.Mean()\n",
        "metrics = [keras.metrics.SparseCategoricalAccuracy()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPqTiRmNOtDz"
      },
      "outputs": [],
      "source": [
        "with trange(1, n_epochs + 1, desc=\"All epochs\") as epochs:\n",
        "    for epoch in epochs:\n",
        "        with trange(1, n_steps + 1, desc=\"Epoch {}/{}\".format(epoch, n_epochs)) as steps:\n",
        "            for step in steps:\n",
        "                X_batch, y_batch = random_batch(X_train, y_train)\n",
        "                with tf.GradientTape() as tape:\n",
        "                    y_pred = model(X_batch)\n",
        "                    main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
        "                    loss = tf.add_n([main_loss] + model.losses)\n",
        "                gradients = tape.gradient(loss, model.trainable_variables)\n",
        "                optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "                for variable in model.variables:\n",
        "                    if variable.constraint is not None:\n",
        "                        variable.assign(variable.constraint(variable))                    \n",
        "                status = OrderedDict()\n",
        "                mean_loss(loss)\n",
        "                status[\"loss\"] = mean_loss.result().numpy()\n",
        "                for metric in metrics:\n",
        "                    metric(y_batch, y_pred)\n",
        "                    status[metric.name] = metric.result().numpy()\n",
        "                steps.set_postfix(status)\n",
        "            y_pred = model(X_valid)\n",
        "            status[\"val_loss\"] = np.mean(loss_fn(y_valid, y_pred))\n",
        "            status[\"val_accuracy\"] = np.mean(keras.metrics.sparse_categorical_accuracy(\n",
        "                tf.constant(y_valid, dtype=np.float32), y_pred))\n",
        "            steps.set_postfix(status)\n",
        "        for metric in [mean_loss] + metrics:\n",
        "            metric.reset_states()\n"
      ]
    }
  ]
}